{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routines for building open cluster graphics based on Gaia DR2 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: Bruno Sampaio Alessi\n",
    "## Since: Aug 09 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "\n",
    "import gc\n",
    "import sys\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import pi\n",
    "from astropy import units\n",
    "from astropy.table import Table\n",
    "from astroquery.vizier import Vizier\n",
    "from astropy.coordinates import SkyCoord\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Input / Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>ra_deg</th>\n",
       "      <th>de_deg</th>\n",
       "      <th>rad_deg</th>\n",
       "      <th>g_mag_lim</th>\n",
       "      <th>large_pm_flag</th>\n",
       "      <th>large_plx_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alessi_10</th>\n",
       "      <td>Aql</td>\n",
       "      <td>301.233</td>\n",
       "      <td>-10.555</td>\n",
       "      <td>0.26583</td>\n",
       "      <td>&lt;17</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Berkeley_61</th>\n",
       "      <td>Cas</td>\n",
       "      <td>12.040</td>\n",
       "      <td>67.199</td>\n",
       "      <td>0.02417</td>\n",
       "      <td>&lt;20</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            const   ra_deg  de_deg  rad_deg g_mag_lim large_pm_flag  \\\n",
       "name                                                                  \n",
       "Alessi_10     Aql  301.233 -10.555  0.26583       <17                 \n",
       "Berkeley_61   Cas   12.040  67.199  0.02417       <20                 \n",
       "\n",
       "            large_plx_flag  \n",
       "name                        \n",
       "Alessi_10                   \n",
       "Berkeley_61                 "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# folders, files, etc\n",
    "# you must have these directories inside the directory which this notebook is located:\n",
    "# /input/data and /input/graphics\n",
    "root_dir   = os.path.join('.','io_files')\n",
    "input_file = os.path.join(root_dir, 'clusters.csv')\n",
    "data_dir   = os.path.join(root_dir, 'data')\n",
    "graph_dir  = os.path.join(root_dir, 'graphics')\n",
    "estim_file = os.path.join(root_dir, 'derived_params.tsv')\n",
    "\n",
    "# input file headers\n",
    "headers = ('name', 'const', 'ra_deg', 'de_deg', 'rad_deg', 'g_mag_lim', 'large_pm_flag', 'large_plx_flag')\n",
    "convs   = {k:str.strip for k in headers}\n",
    "\n",
    "# get filename based on the cluster name in the input file\n",
    "def get_fname(_dir, name, ext):\n",
    "    fname = name.replace(' ','_') + '.' + ext\n",
    "    return os.path.join(_dir, fname)\n",
    "\n",
    "# reads the input file and loads its contents in a DataFrame\n",
    "def get_input_dataframe():\n",
    "    df = pd.read_csv(input_file, converters = convs)\n",
    "    df = df.set_index('name')\n",
    "    df[\"ra_deg\"] = pd.to_numeric(df[\"ra_deg\"])\n",
    "    df[\"de_deg\"] = pd.to_numeric(df[\"de_deg\"])\n",
    "    df[\"rad_deg\"] = pd.to_numeric(df[\"rad_deg\"])\n",
    "    return df\n",
    "\n",
    "# uncomment to check DF contents\n",
    "df = get_input_dataframe()\n",
    "#print(df.dtypes)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Query Gaia DR2 Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaia DR2 catalog on VizieR\n",
    "# see https://vizier.u-strasbg.fr/viz-bin/VizieR-3?-source=I/345/gaia2\n",
    "cat = 'I/345/gaia2'\n",
    "cols = ['_r', 'DR2Name', 'RAdeg', 'DEdeg', 'Plx', 'e_Plx', 'pmRA', 'pmDE', 'Gmag', 'BP-G', 'RV']\n",
    "\n",
    "#Defines the query contraints\n",
    "def get_constraints(name, input_df):\n",
    "    filters = dict()\n",
    "    filters['Plx']   = '-0.5..5'\n",
    "    filters['pmRA']  = '-15..15'\n",
    "    filters['pmDE']  = filters['pmRA']\n",
    "    filters['Gmag']  = input_df.loc[name,'g_mag_lim']\n",
    "    filters['e_Plx'] = '<0.5'\n",
    "    return filters\n",
    "\n",
    "#Returns the coordinates and radius of the area to be queried\n",
    "def get_locus(name, input_df):\n",
    "    ra_deg = input_df.loc[name,'ra_deg']\n",
    "    de_deg = input_df.loc[name,'de_deg']\n",
    "    radius = input_df.loc[name,'rad_deg'] * units.degree\n",
    "    return SkyCoord(ra = ra_deg*units.degree, dec = de_deg*units.degree, frame = 'icrs'), radius\n",
    "\n",
    "#Query the GDR2 data for one cluster\n",
    "def query(name, input_df):\n",
    "    fname = get_fname(data_dir, name, 'tsv')\n",
    "    #checks if the GDR2 data was previously saved locally\n",
    "    #ATTENTION! if you want to re-generate output files (graphics, etc) with other\n",
    "    #set of parameters (e.g. constraints), you need to delete the previously saved files\n",
    "    if os.path.exists(fname):\n",
    "        print(\"Reading existing data for %s ...\" % name)\n",
    "        return pd.read_csv(fname)\n",
    "    print(\"Querying VizieR for %s ...\" % name)\n",
    "    filters  = get_constraints(name, input_df)\n",
    "    coo, rad = get_locus(name, input_df)\n",
    "    viz = Vizier(columns = cols, column_filters = filters, row_limit = 9999, timeout = 300)\n",
    "    viz_res = viz.query_region(coo, radius = rad, catalog = cat)\n",
    "    if viz_res == None or len(viz_res) == 0:\n",
    "        return pd.DataFrame() #Empty Dataframe\n",
    "    return viz_res[0].to_pandas()\n",
    "\n",
    "# TODO:\n",
    "# 1 - create a function to query only one cluster given it's radius and coordinates\n",
    "# 2 - query a larger area to generate a proper RDP (see comments in cell 8)\n",
    "\n",
    "#Save the queried data\n",
    "def save(name, output_df, max_stars = 200):\n",
    "    fname = get_fname(data_dir, name, 'tsv')\n",
    "    output_df = output_df.set_index('DR2Name')\n",
    "    output_df = output_df.sort_values(by='Gmag')\n",
    "    output_df = output_df[:max_stars]\n",
    "    output_df = output_df.sort_values(by='_r')\n",
    "    headers = list(output_df.columns.values)\n",
    "    output_df = output_df[headers[1:] + headers[:1]] #put RV in the last position\n",
    "    if not os.path.exists(fname):\n",
    "        print(\"Writing file %s...\" % fname)\n",
    "        output_df.to_csv(fname, float_format='% .6f')\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Auxiliary routines for tidying graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe it's better to use %-iles to limit and tidy the graphics\n",
    "# instead of setting those clumsy limits - use dataframe.describe?\n",
    "def get_lim_pm(max_pm):\n",
    "    return 15 if max_pm < 15 else \\\n",
    "           20 if max_pm < 20 else \\\n",
    "           25 if max_pm < 25 else \\\n",
    "           30 if max_pm < 30 else \\\n",
    "           35\n",
    "            \n",
    "# Maybe it's better to use %-iles to limit and tidy the graphics\n",
    "# instead of setting those clumsy limits - use dataframe.describe?\n",
    "def get_lim_plx(max_plx):\n",
    "    return 4 if max_plx < 4 else \\\n",
    "           5 if max_plx < 5 else \\\n",
    "           6\n",
    "\n",
    "def filter_pms(pmra, pmde):\n",
    "    return not(-10 < pmra < 10 and -10 < pmde < 10)\n",
    "\n",
    "def filter_plxs(plx):\n",
    "    return plx > 2\n",
    "\n",
    "def pm_limits(pmras, pmdes):\n",
    "    max_pm = np.max([np.abs(np.min(pmras)), np.abs(np.max(pmras))])\n",
    "    lim_pm = get_lim_pm(max_pm)\n",
    "    min_pmRA = -1 * lim_pm\n",
    "    max_pmRA = lim_pm\n",
    "    max_pm = np.max([np.abs(np.min(pmdes)), np.abs(np.max(pmdes))])\n",
    "    lim_pm = get_lim_pm(max_pm)\n",
    "    min_pmDe = -1 * lim_pm\n",
    "    max_pmDe = lim_pm\n",
    "    return min_pmRA, max_pmRA, min_pmDe, max_pmDe\n",
    " \n",
    "def plx_limits(plxs, min_plx = -0.5):\n",
    "    max_plx = np.max(plxs)\n",
    "    max_plx = get_lim_plx(max_plx)\n",
    "    return min_plx, max_plx\n",
    "\n",
    "def mag_limits(gmags, color_mag_incr = 0.5):\n",
    "    min_gmag = np.min(gmags) - color_mag_incr\n",
    "    max_gmag = np.max(gmags) + color_mag_incr\n",
    "    return min_gmag, max_gmag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - VPD scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a VPD (Vector Proper Motion Diagram) scatter plot\n",
    "def plot_VPD(data, cluster_name = None):\n",
    "    pmras = data['pmRA']\n",
    "    pmdes = data['pmDE']\n",
    "    min_pmRA, max_pmRA, min_pmDe, max_pmDe = pm_limits(pmras, pmdes)\n",
    "    xs, ys = pmras, pmdes\n",
    "    plt.xlabel('pmRA (mas/yr)')\n",
    "    plt.ylabel('pmDe (mas/yr)')\n",
    "    plt.xlim(min_pmRA, max_pmRA)\n",
    "    plt.ylim(min_pmDe, max_pmDe)\n",
    "    plt.grid(True, linestyle='dashed')\n",
    "    plt.scatter(xs, ys, s=3, color='black')\n",
    "\n",
    "    \n",
    "# TODO (for this and all graphics below):\n",
    "# create a function generate a unique graphic (instead of grouping it with the other five)\n",
    "# for only one cluster passing the # cluster name, radius and coordinates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Parallax x G mag scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build G mag X Parallax scatter plot\n",
    "def plot_mag_par(data, cluster_name = None):\n",
    "    plxs = data['Plx']\n",
    "    gmags = data['Gmag']\n",
    "    min_gmag, max_gmag = mag_limits(gmags)\n",
    "    min_plx, max_plx = plx_limits(plxs)\n",
    "    xs, ys = gmags, plxs\n",
    "    plt.title(cluster_name)\n",
    "    plt.xlabel('G (mag)')\n",
    "    plt.ylabel('Plx (mas)')\n",
    "    plt.xlim(min_gmag, max_gmag)\n",
    "    plt.ylim(min_plx, max_plx)\n",
    "    plt.grid(True, linestyle='dashed')\n",
    "    plt.scatter(xs, ys, s=3, color='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - CMD scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CMD (Color-Magnitude Diagram) scatter plot\n",
    "def plot_CMD(data, cluster_name = None):\n",
    "    gmags = data['Gmag']\n",
    "    colors = data['BP-G']\n",
    "    min_gmag, max_gmag = mag_limits(gmags)\n",
    "    min_color, max_color = mag_limits(colors)\n",
    "    xs, ys = colors, gmags\n",
    "    plt.xlabel('BP-G (mag)')\n",
    "    plt.ylabel('G (mag)')\n",
    "    plt.xlim(min_color, max_color)\n",
    "    plt.ylim(max_gmag, min_gmag)\n",
    "    plt.grid(True, linestyle='dashed')\n",
    "    plt.scatter(xs, ys, s=3, color='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - RDP scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# This section is unfinished - the generated graphics is fixed and the routines are preliminary\n",
    "# It is necessary to query an area larger than the area defined in cell 3\n",
    "# and draw all graphics but the RDP using the radius and the RDP using the larger\n",
    "# area (an ideally a neighbouring field to trace a line representing the average\n",
    "# backgroun density)\n",
    "\n",
    "def rdp_bins(cl_radius):\n",
    "    max_rad = cl_radius * 8\n",
    "    step = cl_radius / 5\n",
    "    bins = np.arange(0, max_rad, step)\n",
    "    return max_rad, bins\n",
    "\n",
    "def ring_area(inner_rad, outer_rad):\n",
    "    return pi * (outer_rad**2 - inner_rad**2)\n",
    "\n",
    "def rdp_data(counts, bins):\n",
    "    limits = tuple(zip(bins,bins[1:],counts))\n",
    "    mids, dens, errs = [], [], []\n",
    "    for inner, outer, count in limits:\n",
    "        mids.append((inner + outer) / 2)\n",
    "        dens.append(count / ring_area(inner, outer))\n",
    "        errs.append(np.sqrt(dens))\n",
    "    return mids, dens, errs\n",
    "\n",
    "rad = 0.1\n",
    "max_rad, bins = rdp_bins(rad)\n",
    "#print(bins)\n",
    "counts = np.random.randint(10, size=39)\n",
    "max_count = np.max(counts)\n",
    "#print(counts)\n",
    "mids, dens, errs = rdp_data(counts, bins)\n",
    "max_dens = np.max(dens) * 1.1\n",
    "#print(data)\n",
    "\n",
    "# Build RDP (Radial Density Profile) scatter plot\n",
    "def plot_RDP(data, cluster_name = None):\n",
    "    #TODO read data\n",
    "    #pmras = data['pmRA']\n",
    "    \n",
    "    # determine graphic limits\n",
    "    #TODO determine limits\n",
    "    \n",
    "    # plot\n",
    "    plt.grid(True, linestyle='dashed')\n",
    "    xs, ys, yerrs = mids, dens, errs\n",
    "    plt.xlabel('Radius (degrees)')\n",
    "    plt.ylabel('Star Density (stars/deg^2)')\n",
    "    plt.xlim(0, max_rad)\n",
    "    plt.ylim(0, max_dens)\n",
    "    plt.scatter(xs, ys, s=6, color='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 - Parallax Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build 1D Histogram for parallaxes\n",
    "def plot_plx_hist(cluster_name, data, is_lg_plx, step = 0.25):\n",
    "    plxs = data['Plx']\n",
    "    min_plx, max_plx = plx_limits(plxs)\n",
    "    xs = data[data.apply(lambda x: filter_plxs(x['Plx']),axis=1)]['Plx'] if is_lg_plx else plxs\n",
    "    plt.ylabel('N')\n",
    "    plt.xlabel('Plx (mas)')\n",
    "    bins = np.arange(min_plx, max_plx, step)\n",
    "    counts, bins, _ = plt.hist(xs, bins, histtype='bar', ec='black')\n",
    "    idx = np.unravel_index(np.argmax(counts), counts.shape)[0]\n",
    "    return (bins[idx] + bins[idx+1]) / 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 - Proper Motion 2D Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build 2D histogram for proper motions\n",
    "def plot_pm_hist(cluster_name, data, is_lg_pm, num_bins = 20):\n",
    "    data = data[data.apply(lambda x: filter_pms(x['pmRA'],x['pmDE']),axis=1)] if is_lg_pm else data\n",
    "    data = data[data.apply(lambda x: filter_pms(x['pmRA'],x['pmDE']),axis=1)] if is_lg_pm else data\n",
    "    xs = data['pmRA']\n",
    "    ys = data['pmDE']\n",
    "    min_pmRA, max_pmRA, min_pmDe, max_pmDe = pm_limits(xs, ys)\n",
    "    counts, xedges, yedges = np.histogram2d(xs, ys, bins = num_bins, range=[[min_pmRA, max_pmRA], [min_pmDe, max_pmDe]])\n",
    "    x_ind, y_ind = np.unravel_index(np.argmax(counts), counts.shape)\n",
    "    est_pmra = (xedges[x_ind] + xedges[x_ind+1]) / 2\n",
    "    est_pmde = (yedges[y_ind] + yedges[y_ind+1]) / 2\n",
    "    plt.imshow(counts.T, origin='lower')\n",
    "    plt.xlabel('#bin index (pmRA)')\n",
    "    plt.ylabel('#bin index (pmDE)')\n",
    "    plt.plot(x_ind, y_ind, 'or')\n",
    "    return est_pmra, est_pmde\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 - Chart scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Create cluster chart scatter plot (Ra x Dec, in degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 - Plot all graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot everything in a 3 x 3 grid and returns a crude estimate for the cluster proper motion\n",
    "# based on the bin with highest count in the 2D histogram of proper motions\n",
    "def plot(cluster_name, input_df, data):\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    \n",
    "    plt.subplot(231)\n",
    "    plot_VPD(data)\n",
    "    \n",
    "    plt.subplot(232)\n",
    "    plot_mag_par(data, cluster_name)\n",
    "    \n",
    "    plt.subplot(233)\n",
    "    plot_CMD(data)\n",
    "    \n",
    "    plt.subplot(234)\n",
    "    plot_RDP(data)\n",
    "    \n",
    "    plt.subplot(235)\n",
    "    is_lg_plx = input_df.loc[cluster_name,'large_plx_flag']\n",
    "    est_plx = plot_plx_hist(cluster_name, data, is_lg_plx)\n",
    "    \n",
    "    plt.subplot(236)\n",
    "    is_lg_pm = input_df.loc[cluster_name,'large_pm_flag']\n",
    "    est_pmra, est_pmde = plot_pm_hist(cluster_name, data, is_lg_pm)\n",
    "    estimate = f'{cluster_name:<28}; {est_plx:5.2f}; {est_pmra:6.2f}; {est_pmde:6.2f}\\n'\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    file_path_name = get_fname(graph_dir, cluster_name, 'jpg')\n",
    "    fig.savefig(file_path_name, dpi=100)\n",
    "    plt.close('all')\n",
    "    return estimate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 13 - Main routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input parameters from .\\io_files\\clusters.csv ...\n",
      "Generating graphics...\n",
      "Querying VizieR for Alessi_10 ...\n",
      "Writing file .\\io_files\\data\\Alessi_10.tsv...\n",
      "Querying VizieR for Berkeley_61 ...\n",
      "Writing file .\\io_files\\data\\Berkeley_61.tsv...\n",
      "Writing output file .\\io_files\\derived_params.tsv with plx and pm estimates...\n",
      "That's all, folks!\n"
     ]
    }
   ],
   "source": [
    "def process_cluster(cluster_name, input_df, min_stars = 5):\n",
    "    estimate = None\n",
    "    # Query Vizier or read from csv file if previously saved\n",
    "    output_df = query(cluster_name, input_df)\n",
    "    # If the cluster has less than this number, the program will not plot its graphics\n",
    "    if len(output_df.index) < min_stars:\n",
    "        print(\"No data found for %s or it contains less than %d stars\" % (cluster_name, min_stars))\n",
    "    else:\n",
    "        # Tidy and save data in CSV file if not already saved\n",
    "        data = save(cluster_name, output_df)\n",
    "        # Plot graphics and generate estimates\n",
    "        estimate = plot(cluster_name, input_df, data)\n",
    "        del data\n",
    "    del output_df\n",
    "    return estimate\n",
    "\n",
    "def save_estimates(estimates):\n",
    "    if estimates:\n",
    "        #Do not manipulate files directly - put this in a dataframe\n",
    "        print('Writing output file %s with plx and pm estimates...' % estim_file)\n",
    "        with open(estim_file, 'w', encoding='utf8') as f:\n",
    "            f.write('Name;Plx_est;PMRA_est;PMDe_est\\n')\n",
    "            for estimate in estimates:\n",
    "               f.write(estimate)\n",
    "\n",
    "#FIXME:\n",
    "# There is a memory leak that shows if you try to process ~200 clusters ...\n",
    "# I deleted the data frame on each iteration, closed the graphics and\n",
    "# called the garbage collector and the leak still persists\n",
    "\n",
    "cl_estimates = []\n",
    "print('Reading input parameters from %s ...' % input_file)\n",
    "input_df = get_input_dataframe()\n",
    "print('Generating graphics...')\n",
    "for cluster_name in input_df.index:\n",
    "    try:\n",
    "        estimate = process_cluster(cluster_name, input_df)\n",
    "        if estimate:\n",
    "            cl_estimates.append(estimate)\n",
    "        gc.collect()\n",
    "    except:\n",
    "        _type, value, trace = sys.exc_info()\n",
    "        print('Error processing %s: type=%s, value=%s' % (cluster_name, _type, value))\n",
    "        print(trace)\n",
    "        break\n",
    "save_estimates(cl_estimates)\n",
    "\n",
    "print(\"That's all, folks!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
