{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routines for building open cluster graphics based on Gaia DR2 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: Bruno Sampaio Alessi\n",
    "## Since: Aug 09 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "\n",
    "import gc\n",
    "import sys\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import pi\n",
    "from astropy import units\n",
    "from astropy.table import Table\n",
    "from astroquery.vizier import Vizier\n",
    "from astropy.coordinates import SkyCoord\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Input / Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>ra_deg</th>\n",
       "      <th>de_deg</th>\n",
       "      <th>rad_deg</th>\n",
       "      <th>g_mag_lim</th>\n",
       "      <th>large_pm_flag</th>\n",
       "      <th>large_plx_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loden 143</th>\n",
       "      <td>Car</td>\n",
       "      <td>157.183333</td>\n",
       "      <td>-58.821667</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>&lt;15</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ruprecht 159</th>\n",
       "      <td>Car</td>\n",
       "      <td>140.035417</td>\n",
       "      <td>-60.403889</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>&lt;18</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ruprecht 163</th>\n",
       "      <td>Car</td>\n",
       "      <td>166.196667</td>\n",
       "      <td>-67.949167</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>&lt;17</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ruprecht 89</th>\n",
       "      <td>Car</td>\n",
       "      <td>157.110417</td>\n",
       "      <td>-58.179167</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>&lt;15</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ruprecht 90</th>\n",
       "      <td>Car</td>\n",
       "      <td>157.750000</td>\n",
       "      <td>-58.456944</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>&lt;14</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             const      ra_deg     de_deg   rad_deg g_mag_lim large_pm_flag  \\\n",
       "name                                                                          \n",
       "Loden 143      Car  157.183333 -58.821667  0.045833       <15                 \n",
       "Ruprecht 159   Car  140.035417 -60.403889  0.012500       <18                 \n",
       "Ruprecht 163   Car  166.196667 -67.949167  0.018333       <17                 \n",
       "Ruprecht 89    Car  157.110417 -58.179167  0.033333       <15                 \n",
       "Ruprecht 90    Car  157.750000 -58.456944  0.100000       <14                 \n",
       "\n",
       "             large_plx_flag  \n",
       "name                         \n",
       "Loden 143                    \n",
       "Ruprecht 159                 \n",
       "Ruprecht 163                 \n",
       "Ruprecht 89                  \n",
       "Ruprecht 90                  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# folders, files, etc\n",
    "# you must have these directories inside the directory which this notebook is located:\n",
    "# /input/data and /input/graphics\n",
    "root_dir   = os.path.join('.','io_files')\n",
    "input_file = os.path.join(root_dir, 'clusters.csv')\n",
    "data_dir   = os.path.join(root_dir, 'data')\n",
    "graph_dir  = os.path.join(root_dir, 'graphics')\n",
    "estim_file = os.path.join(root_dir, 'derived_params.tsv')\n",
    "\n",
    "# input file headers\n",
    "headers = ('name', 'const', 'ra_deg', 'de_deg', 'rad_deg', 'g_mag_lim', 'large_pm_flag', 'large_plx_flag')\n",
    "convs   = {k:str.strip for k in headers}\n",
    "\n",
    "# get filename based on the cluster name in the input file\n",
    "def get_fname(_dir, name, ext):\n",
    "    fname = name.replace(' ','_') + '.' + ext\n",
    "    return os.path.join(_dir, fname)\n",
    "\n",
    "# reads the input file and loads its contents in a DataFrame\n",
    "def get_input_dataframe():\n",
    "    df = pd.read_csv(input_file, converters = convs)\n",
    "    df = df.set_index('name')\n",
    "    df[\"ra_deg\"] = pd.to_numeric(df[\"ra_deg\"])\n",
    "    df[\"de_deg\"] = pd.to_numeric(df[\"de_deg\"])\n",
    "    df[\"rad_deg\"] = pd.to_numeric(df[\"rad_deg\"])\n",
    "    return df\n",
    "\n",
    "# uncomment to check DF contents\n",
    "df = get_input_dataframe()\n",
    "#print(df.dtypes)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Query Gaia DR2 Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaia DR2 catalog on VizieR\n",
    "# see https://vizier.u-strasbg.fr/viz-bin/VizieR-3?-source=I/345/gaia2\n",
    "cat = 'I/345/gaia2'\n",
    "cols = ['_r', 'DR2Name', 'RAdeg', 'DEdeg', 'Plx', 'e_Plx', 'pmRA', 'pmDE', 'Gmag', 'BP-G', 'RV']\n",
    "\n",
    "#Defines the query contraints\n",
    "def get_constraints(name, input_df):\n",
    "    filters = dict()\n",
    "    filters['Plx']   = '-0.5..5'\n",
    "    filters['pmRA']  = '-15..15'\n",
    "    filters['pmDE']  = filters['pmRA']\n",
    "    filters['Gmag']  = input_df.loc[name,'g_mag_lim']\n",
    "    filters['e_Plx'] = '<0.5'\n",
    "    return filters\n",
    "\n",
    "#Returns the coordinates and radius of the area to be queried\n",
    "def get_locus(name, input_df):\n",
    "    ra_deg = input_df.loc[name,'ra_deg']\n",
    "    de_deg = input_df.loc[name,'de_deg']\n",
    "    radius = input_df.loc[name,'rad_deg'] * units.degree\n",
    "    return SkyCoord(ra = ra_deg*units.degree, dec = de_deg*units.degree, frame = 'icrs'), radius\n",
    "\n",
    "#Query the GDR2 data for one cluster\n",
    "def query(name, input_df):\n",
    "    fname = get_fname(data_dir, name, 'tsv')\n",
    "    #checks if the GDR2 data was previously saved locally\n",
    "    #ATTENTION! if you want to re-generate output files (graphics, etc) with other\n",
    "    #set of parameters (e.g. constraints), you need to delete the previously saved files\n",
    "    if os.path.exists(fname):\n",
    "        print(\"Reading existing data for %s ...\" % name)\n",
    "        return pd.read_csv(fname)\n",
    "    print(\"Querying VizieR for %s ...\" % name)\n",
    "    filters  = get_constraints(name, input_df)\n",
    "    coo, rad = get_locus(name, input_df)\n",
    "    viz = Vizier(columns = cols, column_filters = filters, row_limit = 9999, timeout = 300)\n",
    "    viz_res = viz.query_region(coo, radius = rad, catalog = cat)\n",
    "    if viz_res == None or len(viz_res) == 0:\n",
    "        return pd.DataFrame() #Empty Dataframe\n",
    "    return viz_res[0].to_pandas()\n",
    "\n",
    "# TODO:\n",
    "# 1 - create a function to query only one cluster given it's radius and coordinates\n",
    "# 2 - query a larger area to generate a proper RDP (see comments in cell 8)\n",
    "\n",
    "#Save the queried data\n",
    "def save(name, output_df, max_stars = 200):\n",
    "    fname = get_fname(data_dir, name, 'tsv')\n",
    "    output_df = output_df.set_index('DR2Name')\n",
    "    output_df = output_df.sort_values(by='Gmag')\n",
    "    output_df = output_df[:max_stars]\n",
    "    output_df = output_df.sort_values(by='_r')\n",
    "    headers = list(output_df.columns.values)\n",
    "    output_df = output_df[headers[1:] + headers[:1]] #put RV in the last position\n",
    "    if not os.path.exists(fname):\n",
    "        print(\"Writing file %s...\" % fname)\n",
    "        output_df.to_csv(fname, float_format='% .6f')\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Auxiliary routines for tidying graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe it's better to use %-iles to limit and tidy the graphics\n",
    "# instead of setting those clumsy limits - use dataframe.describe?\n",
    "def get_lim_pm(max_pm):\n",
    "    return 15 if max_pm < 15 else \\\n",
    "           20 if max_pm < 20 else \\\n",
    "           25 if max_pm < 25 else \\\n",
    "           30 if max_pm < 30 else \\\n",
    "           35\n",
    "            \n",
    "# Maybe it's better to use %-iles to limit and tidy the graphics\n",
    "# instead of setting those clumsy limits - use dataframe.describe?\n",
    "def get_lim_plx(max_plx):\n",
    "    return 4 if max_plx < 4 else \\\n",
    "           5 if max_plx < 5 else \\\n",
    "           6\n",
    "\n",
    "def filter_pms(pmra, pmde):\n",
    "    return not(-10 < pmra < 10 and -10 < pmde < 10)\n",
    "\n",
    "def filter_plxs(plx):\n",
    "    return plx > 2\n",
    "\n",
    "def pm_limits(pmras, pmdes):\n",
    "    max_pm = np.max([np.abs(np.min(pmras)), np.abs(np.max(pmras))])\n",
    "    lim_pm = get_lim_pm(max_pm)\n",
    "    min_pmRA = -1 * lim_pm\n",
    "    max_pmRA = lim_pm\n",
    "    max_pm = np.max([np.abs(np.min(pmdes)), np.abs(np.max(pmdes))])\n",
    "    lim_pm = get_lim_pm(max_pm)\n",
    "    min_pmDe = -1 * lim_pm\n",
    "    max_pmDe = lim_pm\n",
    "    return min_pmRA, max_pmRA, min_pmDe, max_pmDe\n",
    " \n",
    "def plx_limits(plxs, min_plx = -0.5):\n",
    "    max_plx = np.max(plxs)\n",
    "    max_plx = get_lim_plx(max_plx)\n",
    "    return min_plx, max_plx\n",
    "\n",
    "def mag_limits(gmags, color_mag_incr = 0.5):\n",
    "    min_gmag = np.min(gmags) - color_mag_incr\n",
    "    max_gmag = np.max(gmags) + color_mag_incr\n",
    "    return min_gmag, max_gmag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - VPD scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a VPD (Vector Proper Motion Diagram) scatter plot\n",
    "def plot_VPD(data, title = None):\n",
    "    pmras = data['pmRA']\n",
    "    pmdes = data['pmDE']\n",
    "    min_pmRA, max_pmRA, min_pmDe, max_pmDe = pm_limits(pmras, pmdes)\n",
    "    xs, ys = pmras, pmdes\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.xlabel('pmRA (mas/yr)')\n",
    "    plt.ylabel('pmDe (mas/yr)')\n",
    "    plt.xlim(min_pmRA, max_pmRA)\n",
    "    plt.ylim(min_pmDe, max_pmDe)\n",
    "    plt.grid(True, linestyle='dashed')\n",
    "    plt.scatter(xs, ys, s=3, color='black')\n",
    "\n",
    "    \n",
    "# TODO (for this and all graphics below):\n",
    "# create a function generate a unique graphic (instead of grouping it with the other five)\n",
    "# for only one cluster passing the # cluster name, radius and coordinates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Parallax x G mag scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build G mag X Parallax scatter plot\n",
    "def plot_mag_par(data, title = None):\n",
    "    plxs = data['Plx']\n",
    "    gmags = data['Gmag']\n",
    "    min_gmag, max_gmag = mag_limits(gmags)\n",
    "    min_plx, max_plx = plx_limits(plxs)\n",
    "    xs, ys = gmags, plxs\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.xlabel('G (mag)')\n",
    "    plt.ylabel('Plx (mas)')\n",
    "    plt.xlim(min_gmag, max_gmag)\n",
    "    plt.ylim(min_plx, max_plx)\n",
    "    plt.grid(True, linestyle='dashed')\n",
    "    plt.scatter(xs, ys, s=3, color='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - CMD scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CMD (Color-Magnitude Diagram) scatter plot\n",
    "def plot_CMD(data, title = None):\n",
    "    gmags = data['Gmag']\n",
    "    colors = data['BP-G']\n",
    "    min_gmag, max_gmag = mag_limits(gmags)\n",
    "    min_color, max_color = mag_limits(colors)\n",
    "    xs, ys = colors, gmags\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.xlabel('BP-G (mag)')\n",
    "    plt.ylabel('G (mag)')\n",
    "    plt.xlim(min_color, max_color)\n",
    "    plt.ylim(max_gmag, min_gmag)\n",
    "    plt.grid(True, linestyle='dashed')\n",
    "    plt.scatter(xs, ys, s=3, color='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - RDP scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# This section is unfinished - the generated graphics is fixed and the routines are preliminary\n",
    "# It is necessary to query an area larger than the area defined in cell 3\n",
    "# and draw all graphics but the RDP using the radius and the RDP using the larger\n",
    "# area (an ideally a neighbouring field to trace a line representing the average\n",
    "# background density)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 - Parallax Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Histogram for parallaxes\n",
    "def plot_plx_hist(data, is_lg_plx, title = None, step = 0.25):\n",
    "    plxs = data['Plx']\n",
    "    xs = data[data.apply(lambda x: filter_plxs(x['Plx']),axis=1)]['Plx'] if is_lg_plx else plxs\n",
    "    min_plx, max_plx = plx_limits(xs)\n",
    "    bins = np.arange(min_plx, max_plx, step)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.ylabel('N')\n",
    "    plt.xlabel('Plx (mas)')\n",
    "    plt.hist(xs, bins, histtype='bar', ec='black')\n",
    "    #counts, bins, _ = plt.hist(xs, bins, histtype='bar', ec='black')\n",
    "    #idx = np.unravel_index(np.argmax(counts), counts.shape)[0]\n",
    "    #return (bins[idx] + bins[idx+1]) / 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 - Proper Motion 2D Histogram (returning PMs for the bin with highest count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the median parallax of the stars within <limit> of the estimated pms\n",
    "def calculate_estimates(data, est_pmra, est_pmde, limit = 3):\n",
    "    filter_fn = lambda x: filter_pms(x['pmRA'],x['pmDE'], est_pmra, est_pmde, limit )\n",
    "    data = data[data.apply(filter_fn, axis = 1)]\n",
    "    plxs = data['Plx']\n",
    "    pmra = data['pmRA']\n",
    "    pmde = data['pmDE']\n",
    "    return np.median(pmra), np.median(pmde), np.median(plxs)\n",
    "\n",
    "def filter_pms(pmra, pmde, est_pmra, est_pmde, limit):\n",
    "    return (abs(est_pmra - pmra) < limit) and (abs(est_pmde - pmde) < limit)\n",
    "\n",
    "# Build 2D histogram for proper motions and returns average PMs for the bin with the highest count\n",
    "def plot_pm_hist(data, is_lg_pm, title = None, num_bins = 20):\n",
    "    data = data[data.apply(lambda x: filter_pms(x['pmRA'],x['pmDE']), axis = 1)] if is_lg_pm else data\n",
    "    xs = data['pmRA']\n",
    "    ys = data['pmDE']\n",
    "    min_pmRA, max_pmRA, min_pmDe, max_pmDe = pm_limits(xs, ys)\n",
    "    counts, xedges, yedges = np.histogram2d(xs, ys, bins = num_bins, range = [[min_pmRA, max_pmRA], [min_pmDe, max_pmDe]])\n",
    "    x_ind, y_ind = np.unravel_index(np.argmax(counts), counts.shape)\n",
    "    est_pmra = (xedges[x_ind] + xedges[x_ind+1]) / 2\n",
    "    est_pmde = (yedges[y_ind] + yedges[y_ind+1]) / 2\n",
    "    plt.imshow(counts.T, origin = 'lower')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.xlabel('pmRA bin index')\n",
    "    plt.ylabel('pmDE bin index')\n",
    "    plt.plot(x_ind, y_ind, 'or')\n",
    "    est_pmra, est_pmde, est_plx = calculate_estimates(data, est_pmra, est_pmde)\n",
    "    return est_pmra, est_pmde, est_plx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 - Chart scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Create cluster chart scatter plot (Ra x Dec, in degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 - Plot all graphics as subplots (and calculates Plx estimate based on PMs in step 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot everything in a 3 x 3 grid and returns a crude estimate for the cluster proper motion\n",
    "# based on the bin with highest count in the 2D histogram of proper motions\n",
    "def plot(cl_name, input_df, data):\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    \n",
    "    plt.subplot(231)\n",
    "    plot_VPD(data)\n",
    "    \n",
    "    plt.subplot(232)\n",
    "    is_lg_pm = input_df.loc[cl_name,'large_pm_flag']\n",
    "    est_pmra, est_pmde, est_plx = plot_pm_hist(data, is_lg_pm, cl_name)\n",
    "    estimates = f'{cluster_name:<28}; {est_plx:5.2f}; {est_pmra:6.2f}; {est_pmde:6.2f}\\n'\n",
    "    \n",
    "    plt.subplot(233)\n",
    "    plot_CMD(data)\n",
    "    \n",
    "    plt.subplot(234)\n",
    "    plot_mag_par(data)\n",
    "    \n",
    "    plt.subplot(235)\n",
    "    is_lg_plx = input_df.loc[cl_name, 'large_plx_flag']\n",
    "    title = f'estimates (plx, pmra, pmde) = ({est_plx:5.2f}, {est_pmra:6.2f}, {est_pmde:6.2f})'\n",
    "    plot_plx_hist(data, is_lg_plx, title)\n",
    "    \n",
    "    #plt.subplot(236)\n",
    "    #plot_RDP(data)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    file_path_name = get_fname(graph_dir, cl_name, 'jpg')\n",
    "    fig.savefig(file_path_name, dpi = 100)\n",
    "    plt.close('all')\n",
    "    return estimates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 13 - Main routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input parameters from .\\io_files\\clusters.csv ...\n",
      "Generating graphics...\n",
      "Querying VizieR for Loden 143 ...\n",
      "Writing file .\\io_files\\data\\Loden_143.tsv...\n",
      "Querying VizieR for Ruprecht 159 ...\n",
      "Writing file .\\io_files\\data\\Ruprecht_159.tsv...\n",
      "Querying VizieR for Ruprecht 163 ...\n",
      "Writing file .\\io_files\\data\\Ruprecht_163.tsv...\n",
      "Querying VizieR for Ruprecht 89 ...\n",
      "Writing file .\\io_files\\data\\Ruprecht_89.tsv...\n",
      "Querying VizieR for Ruprecht 90 ...\n",
      "Writing file .\\io_files\\data\\Ruprecht_90.tsv...\n",
      "Writing output file .\\io_files\\derived_params.tsv with plx and pm estimates...\n",
      "That's all, folks!\n"
     ]
    }
   ],
   "source": [
    "def process_cluster(cluster_name, input_df, min_stars = 5):\n",
    "    estimate = None\n",
    "    # Query Vizier or read from csv file if previously saved\n",
    "    output_df = query(cluster_name, input_df)\n",
    "    # If the cluster has less than this number, the program will not plot its graphics\n",
    "    if len(output_df.index) < min_stars:\n",
    "        print(\"No data found for %s or it contains less than %d stars\" % (cluster_name, min_stars))\n",
    "    else:\n",
    "        # Tidy and save data in CSV file if not already saved\n",
    "        data = save(cluster_name, output_df)\n",
    "        # Plot graphics and generate estimates\n",
    "        estimate = plot(cluster_name, input_df, data)\n",
    "        del data\n",
    "    del output_df\n",
    "    return estimate\n",
    "\n",
    "def save_estimates(estimates):\n",
    "    if estimates:\n",
    "        #Do not manipulate files directly - put this in a dataframe\n",
    "        print('Writing output file %s with plx and pm estimates...' % estim_file)\n",
    "        with open(estim_file, 'w', encoding='utf8') as f:\n",
    "            f.write('Name;Plx_est;PMRA_est;PMDe_est\\n')\n",
    "            for estimate in estimates:\n",
    "               f.write(estimate)\n",
    "\n",
    "#FIXME:\n",
    "# There is a memory leak that shows if you try to process ~200 clusters ...\n",
    "# I deleted the data frame on each iteration, closed the graphics and\n",
    "# called the garbage collector and the leak still persists\n",
    "\n",
    "cl_estimates = []\n",
    "print('Reading input parameters from %s ...' % input_file)\n",
    "input_df = get_input_dataframe()\n",
    "print('Generating graphics...')\n",
    "for cluster_name in input_df.index:\n",
    "    try:\n",
    "        estimate = process_cluster(cluster_name, input_df)\n",
    "        if estimate:\n",
    "            cl_estimates.append(estimate)\n",
    "        gc.collect()\n",
    "    except:\n",
    "        _type, value, trace = sys.exc_info()\n",
    "        print('Error processing %s: type=%s, value=%s' % (cluster_name, _type, value))\n",
    "        print(trace)\n",
    "        break\n",
    "save_estimates(cl_estimates)\n",
    "\n",
    "print(\"That's all, folks!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
